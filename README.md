# Automated ELK Stack Deployment

This project automates the deployment of an ELK Stack (Elasticsearch, Logstash, Kibana) alongside a Java application that generates logs, using Terraform and Ansible. The setup provisions two AWS EC2 instances: one for the ELK stack and another for the Java application, which sends logs to the ELK stack for processing and visualization.

## Prerequisites

Before starting, ensure the following are in place:

- **AWS CLI**: Configured with appropriate permissions to create EC2 instances, security groups, and other resources.
- **Terraform**: Installed (version 1.0.0 or higher).
- **Ansible**: Installed (version 2.9 or higher).
- **WSL Ubuntu**: Used as the Ansible controller (Windows Subsystem for Linux with Ubuntu).
- **AWS Key Pair**: An AWS key pair named `my_default_keypair.pem` stored in `~/.ssh/` with appropriate permissions (chmod 400 ~/.ssh/my_default_keypair.pem).
- **Security Group**: An AWS security group with ID `sg-06759564b372b17fb` (named General_SG) that allows necessary inbound traffic (e.g., ports 22, 5601, 9200, 9300, 5044).

## Directory Structure

The root directory for this project is `elk-auto-deploy`. After running the setup script, the directory structure will look like this:

```
elk-auto-deploy/
├── setup.sh
├── deploy.sh
├── terraform/
│   ├── main.tf
│   ├── inventory.tmpl
│   └── vars.tmpl
└── ansible/
    ├── site.yml
    ├── templates/
    │   ├── elasticsearch.yml.j2
    │   ├── logstash.conf.j2
    │   ├── kibana.yml.j2
    │   └── filebeat.yml.j2
    ├── inventory (generated by Terraform)
    └── group_vars/
        └── all.yml (generated by Terraform)
```

- `setup.sh`: Creates the directory structure and generates all necessary configuration files.
- `deploy.sh`: Executes the deployment by running Terraform and Ansible.
- `terraform/`: Contains Terraform configuration files to provision AWS infrastructure.
- `ansible/`: Contains Ansible playbooks and templates to configure the ELK stack and Java application.
- `ansible/inventory` and `ansible/group_vars/all.yml`: Dynamically generated by Terraform during deployment.

## Setup Instructions

Follow these steps to set up and deploy the ELK stack automation:

1. **Clone the Repository (if applicable)**:
   If this project is hosted on GitHub, clone the repository to your local machine:
   ```bash
   git clone <repository-url>
   cd elk-auto-deploy
   ```

   Alternatively, create the root directory manually:
   ```bash
   mkdir elk-auto-deploy
   cd elk-auto-deploy
   ```

2. **Create and Run the Setup Script**:
   - Create a file named `setup.sh` in the elk-auto-deploy directory and copy the provided setup.sh script into it.
   - Make the script executable:
     ```bash
     chmod +x setup.sh
     ```
   - Run the setup script to generate the directory structure and configuration files:
     ```bash
     ./setup.sh
     ```

   This script will:
   - Create the directory structure: `terraform/`, `ansible/templates/`, and `ansible/group_vars/`.
   - Generate Terraform files: `main.tf`, `inventory.tmpl`, and `vars.tmpl`.
   - Generate Ansible files: `site.yml` and templates (`elasticsearch.yml.j2`, `logstash.conf.j2`, `kibana.yml.j2`, `filebeat.yml.j2`).
   - Create the deployment script `deploy.sh` and make it executable.

3. **Run the Deployment Script**:
   After setup.sh completes, run the deploy.sh script to deploy the infrastructure and configure the ELK stack:
   ```bash
   ./deploy.sh
   ```

   This script will:
   - Initialize and apply the Terraform configuration to provision two EC2 instances.
   - Wait 90 seconds for the servers to be ready.
   - Run the Ansible playbook to configure both servers, including installing the ELK stack components, deploying the Java application, and setting up log forwarding.

![image](https://github.com/user-attachments/assets/d1b6c73f-89c8-4956-a94a-c78b8382f5b8)

![image](https://github.com/user-attachments/assets/6e8c2638-cd6d-4457-8402-11bc05ace2ec)

![image](https://github.com/user-attachments/assets/bd377125-e2a6-43ad-be4f-42c93ac38c27)


4. **Access Kibana**:
   Once the deployment completes, the script will output the Kibana URL. Access Kibana in your browser at:
   ```
   http://<elk-server-public-ip>:5601
   ```

   ![image](https://github.com/user-attachments/assets/3b869950-251f-4eaf-8ae6-cf792105c567)


   To view logs in Kibana:
   - Go to Stack Management > Index Patterns.
   - Create an index pattern for logs-* (e.g., logs-2025.04.*).
   - Navigate to Discover to view the logs generated by the Java application.
  
  ![image](https://github.com/user-attachments/assets/9befacc6-835c-4928-b513-912a36e39fa8)

  ![image](https://github.com/user-attachments/assets/37ef459b-c11e-4d41-8f0b-adb6089c10c0)



## Deployment Details

### Components

#### Terraform:
- Provisions two EC2 instances running Ubuntu 24.04 LTS:
  - **ELK Server**: A t3.large instance (at least 4GB RAM) for running Elasticsearch, Logstash, and Kibana.
  - **Client Machine**: A t2.micro instance for running the Java application.
- Uses the AMI `ami-084568db4383264d4` (Ubuntu 24.04 LTS in us-east-1).
- Attaches both instances to the security group `sg-06759564b372b17fb`.
- Generates an Ansible inventory file (`ansible/inventory`) and variables file (`ansible/group_vars/all.yml`) dynamically.

#### Ansible:
- **Configures the ELK server**:
  - Installs Elasticsearch 7.17.0, Logstash 7.17.0, and Kibana 7.17.0.
  - Configures Elasticsearch with a single-node cluster, 2GB JVM heap, and proper file permissions.
  - Sets up Logstash to receive logs from Filebeat (port 5044) and forward them to Elasticsearch.
  - Configures Kibana to connect to Elasticsearch and listen on port 5601.

- **Configures the client machine**:
  - Installs Java (OpenJDK 17) and Maven.
  - Clones the Java application repository (https://github.com/felix-momodebe-official/maven-web-app.git).
  - Builds and runs the application using Maven Jetty, logging to `/home/ubuntu/maven-web-app/target/app.log`.
  - Installs and configures Filebeat 7.17.0 to forward logs to Logstash on the ELK server.

#### Java Application:
- A Maven-based web application pulled from https://github.com/felix-momodebe-official/maven-web-app.git.
- Built and run using `mvn jetty:run`, generating logs in `/home/ubuntu/maven-web-app/target/app.log`.
- Logs are collected by Filebeat and sent to Logstash for processing.

#### ELK Stack:
- **Elasticsearch**: Stores and indexes logs in indices like logs-YYYY.MM.dd.
- **Logstash**: Processes logs received from Filebeat, parsing them with a grok filter, and forwards them to Elasticsearch.
- **Kibana**: Provides a web interface to visualize logs at http://<elk-server-public-ip>:5601.

### Log Flow

1. The Java application on the client machine generates logs in `/home/ubuntu/maven-web-app/target/app.log`.
2. Filebeat on the client machine collects these logs and forwards them to Logstash on the ELK server (port 5044).
3. Logstash processes the logs using a grok filter to parse timestamps, log levels, and messages.
4. Logstash sends the parsed logs to Elasticsearch, which stores them in daily indices (logs-YYYY.MM.dd).
5. Kibana connects to Elasticsearch to display the logs in a user-friendly interface.

## Troubleshooting

### Logs Not Visible in Kibana:

- Verify that the Java application is running on the client machine:
  ```bash
  ssh -i ~/.ssh/my_default_keypair.pem ubuntu@<client-public-ip> "ps aux | grep jetty"
  ```
- Check the contents of the log file:
  ```bash
  ssh -i ~/.ssh/my_default_keypair.pem ubuntu@<client-public-ip> "cat /home/ubuntu/maven-web-app/target/app.log"
  ```
- Ensure Filebeat is running on the client machine:
  ```bash
  ssh -i ~/.ssh/my_default_keypair.pem ubuntu@<client-public-ip> "sudo systemctl status filebeat"
  ```
- Ensure Logstash is running on the ELK server:
  ```bash
  ssh -i ~/.ssh/my_default_keypair.pem ubuntu@<elk-public-ip> "sudo systemctl status logstash"
  ```
- Check Elasticsearch indices:
  ```bash
  curl http://<elk-private-ip>:9200/_cat/indices?v
  ```

### Ansible Playbook Fails:
- Review the Ansible output for specific errors.
- Ensure the AWS key pair file (`~/.ssh/my_default_keypair.pem`) has the correct permissions (chmod 400).
- Verify that the security group allows necessary ports (22, 5601, 9200, 9300, 5044).

### Terraform Fails:
- Check AWS credentials and permissions.
- Ensure the specified AMI and security group exist in the us-east-1 region.

## Teardown

To remove all created resources and clean up:

1. Navigate to the Terraform directory:
   ```bash
   cd terraform
   ```

2. Destroy the infrastructure:
   ```bash
   terraform destroy -auto-approve
   ```

This will terminate the EC2 instances and remove any resources created by Terraform.

## Notes

- The ELK server requires at least 4GB of RAM, which is why a t3.large instance is used.
- The client machine uses a t2.micro instance, sufficient for running the Java application.
- The Java application's Maven build process (`mvn clean package`) will overwrite any existing target folder.
- Logs are stored in Elasticsearch with a daily index pattern (logs-YYYY.MM.dd), making it easy to manage and query.
- Ensure your security group (`sg-06759564b372b17fb`) allows inbound traffic on the necessary ports for SSH (22), Kibana (5601), Elasticsearch (9200, 9300), and Logstash (5044).
